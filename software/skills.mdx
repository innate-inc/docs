---
title: "Skills"
---

Skills are atomic robot capabilities that BASIC chains together to accomplish complex, long-horizon behaviors. Each skill encodes a single capability—physical (manipulation, navigation) or digital (emails, API calls)—that can be combined with others to form coherent action sequences.

When BASIC receives a request like "check on grandma," it decomposes this into a skill chain: navigate to bedroom → look around → send picture via email → speak reassurance. Four skills, one coherent behavior.

## Two Types of Skills

Skills are defined in one of two ways:

### Code-Defined Skills

Python classes that implement explicit logic. The AI agent reads your code's function signature and docstrings to understand what the skill does and how to call it.

Interfaces are declared at class level and injected by the runtime. In `execute()`, use them directly via `self.<interface_name>`.

```python
import math
from brain_client.skill_types import Skill, SkillResult, Interface, InterfaceType

class LookAround(Skill):
    # Declared once, injected automatically
    mobility = Interface(InterfaceType.MOBILITY)
    head = Interface(InterfaceType.HEAD)

    @property
    def name(self):
        return "look_around"

    def execute(self, num_directions: int = 4):
        """Rotate and scan the environment."""
        if self.mobility is None or self.head is None:
            return "Required interfaces not available", SkillResult.FAILURE

        num_directions = max(1, num_directions)
        self.head.set_position(-15)  # Look down
        self.mobility.rotate((2 * math.pi) / num_directions)
        return "Scan complete", SkillResult.SUCCESS

    def cancel(self):
        return "Cancelled"
```

Use code-defined skills for:

* **Physical behaviors** — Direct control of base, arm, and head

* **Digital operations** — Emails, API calls, web services

* **Coordinated behaviors** — Sequencing multiple actions with explicit logic

* **Sensor processing** — Vision, scanning, object detection

### Policy-Defined Skills (End-to-End)

Neural network policies trained from demonstration. Currently uses **ACT (Action Chunking with Transformers)** for manipulation tasks.

```json
{
    "name": "pick_cup",
    "type": "learned",
    "guidelines": "Use when you need to pick up a cup",
    "execution": {
        "model_type": "act_policy",
        "checkpoint": "policy_step_50000.pth"
    }
}
```

Use policy-defined skills for:

* **Manipulation** — Picking, placing, grasping objects

* **Tasks requiring visual adaptation** — The policy reacts to what it sees

* **Behaviors hard to express in code** — Complex motions learned from demonstration

See [Policy-Defined Skills](/software/skills/policy-defined-skills) for details on creating and training learned skills.

## Documentation

### Code-Defined Skills

* [**Overview**](/software/skills/code-defined-skills) — Principles and the Skill class

* [**Navigation Interfaces**](/software/skills/code-defined-skills/navigation-interfaces) — Mobility control, rotation, velocity commands

* [**Body Control Interfaces**](/software/skills/code-defined-skills/body-control-interfaces) — Arm manipulation, head movement, IK

* [**Robot State**](/software/skills/code-defined-skills/robot-state) — Camera, odometry, map, sensor data

* [**Physical Skill Examples**](/software/skills/code-defined-skills/physical-skill-examples) — Full-body behaviors using nav + manipulation

* [**Digital Skills**](/software/skills/code-defined-skills/digital-skills) — APIs, email, web services, external agents

### Policy-Defined Skills

* [**Overview**](/software/skills/policy-defined-skills) — Training and deploying learned manipulation skills

## Skill Directories

Skills are auto-discovered from two directories:

Directory

Purpose

`~/skills/`

**Your skills** — put custom skills here

`innate-os/skills/`

**Built-in skills** — templates and examples, don't modify

Skill Type

Format

Code-defined

`*.py` — Python class extending `Skill`

Policy-defined

`<name>/metadata.json` — JSON metadata + model checkpoint

No registration required. Drop a file in the right place and the robot loads it on startup.
